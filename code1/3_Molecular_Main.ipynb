{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electric-honolulu",
   "metadata": {},
   "source": [
    "## Code from\n",
    "\n",
    "<< https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter >>\n",
    "* Kaggle : Y.Nakama, yasufuminakama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-light",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "corporate-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, Blur\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "import Levenshtein\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-causing",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modern-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0 cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() : \n",
    "    DEVICE = torch.device('cuda')\n",
    "else : \n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print(torch.__version__, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "sized-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of Memory 해결 법\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-breath",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "tested-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "TRAIN_DIR = PATH + 'train'\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "class CFG : \n",
    "    debug = False\n",
    "    max_len = 275\n",
    "    print_freq = 1000\n",
    "    num_workers = 0\n",
    "    model_name = 'resnet34'\n",
    "    size = 224\n",
    "    scheduler='CosineAnnealingLR'\n",
    "    epochs = 1\n",
    "    T_max = 4 \n",
    "    encoder_lr = 1e-4\n",
    "    decoder_lr = 4e-4\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 16\n",
    "    weight_decay = 1e-6\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 5\n",
    "    attention_dim = 256\n",
    "    embed_dim = 256\n",
    "    decoder_dim = 512\n",
    "    dropout = 0.5\n",
    "    seed = 0\n",
    "    n_fold = 5\n",
    "    trn_fold = [0]\n",
    "    train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "substantial-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-maple",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valuable-mission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChI_1</th>\n",
       "      <th>InChI_text</th>\n",
       "      <th>InChI_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>C13H20OS</td>\n",
       "      <td>C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>C21H30O4</td>\n",
       "      <td>C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>C24H23N5O4</td>\n",
       "      <td>C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>C17H24N2O4S</td>\n",
       "      <td>C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>C10H19N3O2S</td>\n",
       "      <td>C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "       InChI_1                                         InChI_text  \\\n",
       "0     C13H20OS  C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...   \n",
       "1     C21H30O4  C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...   \n",
       "2   C24H23N5O4  C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...   \n",
       "3  C17H24N2O4S  C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...   \n",
       "4  C10H19N3O2S  C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...   \n",
       "\n",
       "   InChI_length  \n",
       "0            59  \n",
       "1           108  \n",
       "2           112  \n",
       "3           108  \n",
       "4            72  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('train2.pkl')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yellow-former",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.stoi: {'(': 0, ')': 1, '+': 2, ',': 3, '-': 4, '/b': 5, '/c': 6, '/h': 7, '/i': 8, '/m': 9, '/s': 10, '/t': 11, '0': 12, '1': 13, '10': 14, '100': 15, '101': 16, '102': 17, '103': 18, '104': 19, '105': 20, '106': 21, '107': 22, '108': 23, '109': 24, '11': 25, '110': 26, '111': 27, '112': 28, '113': 29, '114': 30, '115': 31, '116': 32, '117': 33, '118': 34, '119': 35, '12': 36, '120': 37, '121': 38, '122': 39, '123': 40, '124': 41, '125': 42, '126': 43, '127': 44, '128': 45, '129': 46, '13': 47, '130': 48, '131': 49, '132': 50, '133': 51, '134': 52, '135': 53, '136': 54, '137': 55, '138': 56, '139': 57, '14': 58, '140': 59, '141': 60, '142': 61, '143': 62, '144': 63, '145': 64, '146': 65, '147': 66, '148': 67, '149': 68, '15': 69, '150': 70, '151': 71, '152': 72, '153': 73, '154': 74, '155': 75, '156': 76, '157': 77, '158': 78, '159': 79, '16': 80, '161': 81, '163': 82, '165': 83, '167': 84, '17': 85, '18': 86, '19': 87, '2': 88, '20': 89, '21': 90, '22': 91, '23': 92, '24': 93, '25': 94, '26': 95, '27': 96, '28': 97, '29': 98, '3': 99, '30': 100, '31': 101, '32': 102, '33': 103, '34': 104, '35': 105, '36': 106, '37': 107, '38': 108, '39': 109, '4': 110, '40': 111, '41': 112, '42': 113, '43': 114, '44': 115, '45': 116, '46': 117, '47': 118, '48': 119, '49': 120, '5': 121, '50': 122, '51': 123, '52': 124, '53': 125, '54': 126, '55': 127, '56': 128, '57': 129, '58': 130, '59': 131, '6': 132, '60': 133, '61': 134, '62': 135, '63': 136, '64': 137, '65': 138, '66': 139, '67': 140, '68': 141, '69': 142, '7': 143, '70': 144, '71': 145, '72': 146, '73': 147, '74': 148, '75': 149, '76': 150, '77': 151, '78': 152, '79': 153, '8': 154, '80': 155, '81': 156, '82': 157, '83': 158, '84': 159, '85': 160, '86': 161, '87': 162, '88': 163, '89': 164, '9': 165, '90': 166, '91': 167, '92': 168, '93': 169, '94': 170, '95': 171, '96': 172, '97': 173, '98': 174, '99': 175, 'B': 176, 'Br': 177, 'C': 178, 'Cl': 179, 'D': 180, 'F': 181, 'H': 182, 'I': 183, 'N': 184, 'O': 185, 'P': 186, 'S': 187, 'Si': 188, 'T': 189, '<sos>': 190, '<eos>': 191, '<pad>': 192}\n"
     ]
    }
   ],
   "source": [
    "# Code From https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter\n",
    "\n",
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        vocab = set()\n",
    "        for text in texts:\n",
    "            vocab.update(text.split(' '))\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        self.itos = {item[1]: item[0] for item in self.stoi.items()}\n",
    "        \n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = []\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        return sequence\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = self.text_to_sequence(text)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = self.sequence_to_text(sequence)\n",
    "            texts.append(text)\n",
    "        return texts\n",
    "    \n",
    "    def predict_caption(self, sequence):\n",
    "        caption = ''\n",
    "        for i in sequence:\n",
    "            if i == self.stoi['<eos>'] or i == self.stoi['<pad>']:\n",
    "                break\n",
    "            caption += self.itos[i]\n",
    "        return caption\n",
    "    \n",
    "    def predict_captions(self, sequences):\n",
    "        captions = []\n",
    "        for sequence in sequences:\n",
    "            caption = self.predict_caption(sequence)\n",
    "            captions.append(caption)\n",
    "        return captions\n",
    "\n",
    "tokenizer = torch.load('tokenizer2.pth')\n",
    "print(f\"tokenizer.stoi: {tokenizer.stoi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coated-terry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['InChI_length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "terminal-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(img_name) : \n",
    "    return f\"{TRAIN_DIR}/{img_name[0]}/{img_name[1]}/{img_name[2]}/{img_name}.png\"\n",
    "\n",
    "train['path'] = train['image_id'].apply(get_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unique-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChI_1</th>\n",
       "      <th>InChI_text</th>\n",
       "      <th>InChI_length</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>C13H20OS</td>\n",
       "      <td>C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...</td>\n",
       "      <td>59</td>\n",
       "      <td>./data/train/0/0/0/000011a64c74.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>C21H30O4</td>\n",
       "      <td>C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...</td>\n",
       "      <td>108</td>\n",
       "      <td>./data/train/0/0/0/000019cc0cd2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>C24H23N5O4</td>\n",
       "      <td>C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...</td>\n",
       "      <td>112</td>\n",
       "      <td>./data/train/0/0/0/0000252b6d2b.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>C17H24N2O4S</td>\n",
       "      <td>C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...</td>\n",
       "      <td>108</td>\n",
       "      <td>./data/train/0/0/0/000026b49b7e.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>C10H19N3O2S</td>\n",
       "      <td>C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...</td>\n",
       "      <td>72</td>\n",
       "      <td>./data/train/0/0/0/000026fc6c36.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "       InChI_1                                         InChI_text  \\\n",
       "0     C13H20OS  C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...   \n",
       "1     C21H30O4  C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...   \n",
       "2   C24H23N5O4  C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...   \n",
       "3  C17H24N2O4S  C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...   \n",
       "4  C10H19N3O2S  C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...   \n",
       "\n",
       "   InChI_length                                 path  \n",
       "0            59  ./data/train/0/0/0/000011a64c74.png  \n",
       "1           108  ./data/train/0/0/0/000019cc0cd2.png  \n",
       "2           112  ./data/train/0/0/0/0000252b6d2b.png  \n",
       "3           108  ./data/train/0/0/0/000026b49b7e.png  \n",
       "4            72  ./data/train/0/0/0/000026fc6c36.png  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ignored-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset) : \n",
    "    def __init__(self, df, tokenizer, transform) :\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) : \n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index) : \n",
    "        image_name = self.df.image_id.iloc[index]\n",
    "        image = cv2.imread(self.df.path.iloc[index])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        augmented = self.transform(image = image)\n",
    "        image = augmented['image']\n",
    "        \n",
    "        label = self.df.InChI_text.iloc[index]\n",
    "        label = self.tokenizer.text_to_sequence(label)\n",
    "        label_length = len(label)\n",
    "        label_length = torch.LongTensor([label_length])\n",
    "        return image, torch.LongTensor(label), label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "technical-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset) : \n",
    "    def __init__(self, df, transform = None) : \n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) : \n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx) : \n",
    "        path = self.df.path.iloc[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        augmented = self.transform(image = image)\n",
    "        image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlikely-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform = Compose([\n",
    "    Resize(CFG.size, CFG.size),\n",
    "    Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std = [0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "egyptian-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TrainDataset(train, tokenizer, Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "macro-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1) : \n",
    "    image, label, label_length = trainset[i]\n",
    "    text = tokenizer.sequence_to_text(label.numpy())\n",
    "    plt.imshow(image.transpose(0, 1).transpose(1, 2))\n",
    "    plt.title(f'label: {label}  text: {text}  label_length: {label_length}')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-ratio",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acceptable-legislature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(CFG.model_name, pretrained = False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wrapped-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "shape : torch.Size([2, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Identity()\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_test_val = torch.randn(2, 3, 224, 224)\n",
    "print(out_test_val.shape)\n",
    "out_test = model(out_test_val)\n",
    "print(f'shape : {out_test.shape}')\n",
    "model.global_pool = nn.Identity()\n",
    "model.fc = nn.Identity()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "charming-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) : \n",
    "    def __init__(self, model_name = 'resnet34', pretrained = False) :\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model(model_name, pretrained = pretrained)\n",
    "        self.n_features = self.cnn.fc.in_features\n",
    "        self.cnn.global_pool = nn.Identity()\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        bs = x.size(0)\n",
    "        features = self.cnn(x)\n",
    "        features = features.permute(0, 2, 3, 1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-discipline",
   "metadata": {},
   "source": [
    "feature 크기가 안맞음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affiliated-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module) : \n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim) : \n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)\n",
    "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)\n",
    "        self.full_att = nn.Linear(attention_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, encoder_out, decoder_hidden) : \n",
    "        att1 = self.encoder_att(encoder_out)\n",
    "        att2 = self.decoder_att(decoder_hidden)\n",
    "        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)\n",
    "        alpha = self.softmax(att)\n",
    "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim = 1)\n",
    "        return attention_weighted_encoding, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "distant-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithAttention(nn.Module) : \n",
    "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, device, encoder_dim = 512, dropout = 0.5) : \n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        self.attention = Attention(encoder_dim, decoder_dim, attention_dim)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.dropout = nn.Dropout(p = self.dropout)\n",
    "        self.decode_step = nn.LSTMCell(embed_dim + encoder_dim, decoder_dim, bias = True)\n",
    "        self.init_h = nn.Linear(encoder_dim, decoder_dim)\n",
    "        self.init_c = nn.Linear(encoder_dim, decoder_dim)\n",
    "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(decoder_dim, vocab_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self) : \n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings) : \n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tune_embeddings(self, fine_tune = True) : \n",
    "        for p in self.embedding.parameters() : \n",
    "            p.requires_grad = fine_tune\n",
    "            \n",
    "    def init_hidden_state(self, encoder_out) : \n",
    "        mean_encoder_out = encoder_out.mean(dim = 1)\n",
    "        h = self.init_h(mean_encoder_out)\n",
    "        c = self.init_c(mean_encoder_out)\n",
    "        return h, c\n",
    "    \n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths) : \n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)\n",
    "        num_pixels = encoder_out.size(1)\n",
    "        \n",
    "        caption_length, sort_ind = caption_lengths.squeeze(1).sort(dim = 0, descending = True)\n",
    "        encoder_out = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "        embeddings = self.embedding(encoded_captions)\n",
    "        \n",
    "        h, c = self.init_hidden_state(encoder_out)\n",
    "        \n",
    "        decode_lengths = (caption_length - 1).tolist()\n",
    "        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(self.device)\n",
    "        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(self.device)\n",
    "        \n",
    "        for t in range(max(decode_lengths)) : \n",
    "            batch_size_t = sum([l > t for l in decode_lengths])\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t], h[:batch_size_t])\n",
    "            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            h, c = self.decode_step(torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim = 1),\n",
    "                                   (h[:batch_size_t], c[:batch_size_t]))\n",
    "            preds = self.fc(self.dropout(h))\n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "            alphas[:batch_size_t, t, :] = alpha\n",
    "            \n",
    "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind\n",
    "    \n",
    "    def predict(self, encoder_out, decode_lengths, tokenizer) : \n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)\n",
    "        num_pixels = encoder_out.size(1)\n",
    "        \n",
    "        start_tockens = torch.ones(batch_size, dtype = torch.long).to(self.device) * tokenizer.stoi[\"<sos>\"]\n",
    "        embeddings = self.embedding(start_tockens)\n",
    "        h, c = self.init_hidden_state(encoder_out)\n",
    "        predictions = torch.zeros(batch_size, decode_lengths, vocab_size).to(self.device)\n",
    "        \n",
    "        for t in range(decode_lengths) : \n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out, h)\n",
    "            gate = self.sigmoid(self.f_beta(h))\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            h, c = self.decode_step(torch.cat([embeddings, attention_weighted_encoding], dim = 1),\n",
    "                                   (h, c))\n",
    "            preds = self.fc(self.dropout(h))\n",
    "            predictions[:, t, :] = preds\n",
    "            \n",
    "            if np.argmax(preds.detach().cpu().numpy() == tokenizer.stoi[\"<eos>\"]) : \n",
    "                break\n",
    "                \n",
    "            embeddings = self.embedding(torch.argmax(preds, -1))\n",
    "        return predictions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wired-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3590e+00,  1.4441e+00, -1.1384e+00,  ..., -6.9568e-01,\n",
      "         -3.9267e-01,  5.2665e-02],\n",
      "        [ 1.5229e+00,  1.2978e-01, -1.3078e-01,  ...,  1.9092e+00,\n",
      "         -9.0539e-02,  1.7844e-01],\n",
      "        [ 5.1041e-01, -6.6608e-01,  4.5714e-01,  ...,  5.2256e-01,\n",
      "          6.0595e-01,  7.8811e-01],\n",
      "        ...,\n",
      "        [-2.2162e+00,  7.6062e-01,  1.6445e+00,  ...,  2.7885e-01,\n",
      "          7.6472e-01, -2.1954e-01],\n",
      "        [-4.2373e-01, -5.5159e-01, -2.9657e+00,  ..., -1.3615e+00,\n",
      "          6.0430e-01,  7.2182e-01],\n",
      "        [ 3.7746e-01,  4.4349e-01, -1.0430e+00,  ..., -4.9108e-01,\n",
      "          1.0661e+00,  9.0648e-05]])\n",
      "tensor([[ 0.0432, -0.0519,  0.0568,  ...,  0.0788, -0.0579,  0.0184],\n",
      "        [-0.0188,  0.0552, -0.0670,  ...,  0.0885,  0.0766,  0.0682],\n",
      "        [-0.0841,  0.0961,  0.0265,  ..., -0.0469, -0.0735, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0724,  0.0654, -0.0564,  ...,  0.0839,  0.0987,  0.0719],\n",
      "        [-0.0218, -0.0901,  0.0120,  ..., -0.0148,  0.0370, -0.0148],\n",
      "        [ 0.0858,  0.0499,  0.0556,  ...,  0.0673,  0.0227, -0.0194]])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(30, 512)\n",
    "print(embedding.weight.data)\n",
    "print(embedding.weight.data.uniform_(-0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "resident-council",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0301,  0.0238,  0.0029, -0.0391,  0.0263, -0.0181,  0.0389, -0.0014,\n",
       "         0.0014, -0.0090, -0.0212,  0.0014,  0.0052,  0.0150, -0.0096, -0.0041,\n",
       "        -0.0211,  0.0124,  0.0297, -0.0251, -0.0082,  0.0298, -0.0408, -0.0002,\n",
       "         0.0160,  0.0003, -0.0123, -0.0374,  0.0436, -0.0412])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(512, 30)\n",
    "fc.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "measured-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3044,  0.7540, -1.5177,  ...,  0.6235, -0.0899,  3.0908],\n",
      "          [ 0.5901, -1.4152, -0.2312,  ..., -1.8907,  1.9177,  0.5691],\n",
      "          [-0.3886, -1.4381, -0.8307,  ..., -0.4119, -0.5074,  1.1393],\n",
      "          ...,\n",
      "          [-0.4840, -1.0250, -0.4982,  ...,  0.6701,  0.2114,  1.4567],\n",
      "          [ 1.4101,  0.9289,  0.6544,  ...,  2.7610,  0.2670, -0.0039],\n",
      "          [ 2.0325, -0.2024, -2.0813,  ...,  1.2517,  1.5438,  0.1431]],\n",
      "\n",
      "         [[ 0.6788, -0.6160, -0.0460,  ...,  1.2763, -0.9281,  0.4504],\n",
      "          [-1.5570, -0.1272,  2.0995,  ...,  0.5402,  0.5966,  0.8183],\n",
      "          [ 1.2140,  2.6829, -0.4258,  ...,  0.5324, -1.4423, -1.2142],\n",
      "          ...,\n",
      "          [-0.4453, -0.6367,  1.1478,  ..., -1.4535, -2.4058,  0.4512],\n",
      "          [-0.7411, -0.2841, -0.1344,  ...,  0.9410, -0.1128, -0.9692],\n",
      "          [-1.0666, -0.2804, -0.9853,  ..., -0.4616, -0.9477, -0.3935]],\n",
      "\n",
      "         [[ 0.5055, -0.6264,  0.4532,  ...,  0.8404,  1.7172,  0.7068],\n",
      "          [-0.1991,  1.0388,  1.0157,  ..., -1.3901, -1.8518, -0.5196],\n",
      "          [-0.6752, -1.1405,  0.5670,  ...,  1.0066,  0.4512,  0.1531],\n",
      "          ...,\n",
      "          [-0.6310, -0.1000,  0.3842,  ..., -0.8271, -0.5949,  1.2789],\n",
      "          [-0.2688,  0.5778, -0.0246,  ..., -0.1167,  1.1109,  0.6747],\n",
      "          [ 1.5399,  0.3914, -1.5289,  ..., -0.4791, -0.7300,  0.4437]]],\n",
      "\n",
      "\n",
      "        [[[-2.3989,  0.1256,  0.8555,  ...,  0.5750, -1.0436,  0.4934],\n",
      "          [ 0.7335,  0.3081,  1.0395,  ...,  0.0177,  1.0942,  0.6037],\n",
      "          [ 2.0948,  1.5887, -0.1003,  ...,  0.0204,  1.1576, -0.1042],\n",
      "          ...,\n",
      "          [-1.0514,  0.6295, -0.8055,  ..., -2.5075, -0.9646, -0.1401],\n",
      "          [-0.3995,  0.4450, -1.3803,  ..., -1.4225,  1.5039,  0.1247],\n",
      "          [-0.1091,  0.4499,  0.7655,  ...,  0.6336, -0.0476,  2.3477]],\n",
      "\n",
      "         [[ 1.8175,  0.9484,  0.3751,  ..., -0.8077,  1.0218,  1.3239],\n",
      "          [-2.1371, -0.9305,  1.5929,  ..., -0.9087, -0.5195,  0.7040],\n",
      "          [ 0.7619, -0.8183,  1.0030,  ...,  0.1921,  1.0271, -0.2522],\n",
      "          ...,\n",
      "          [-1.0584, -0.1344, -0.9631,  ...,  0.9484,  2.2136, -0.5076],\n",
      "          [-1.5460,  0.6247,  0.1021,  ..., -1.4688, -0.2744, -0.1154],\n",
      "          [ 0.1468, -0.2053, -2.0332,  ..., -0.9090, -0.0336,  0.9345]],\n",
      "\n",
      "         [[ 1.9661, -0.0551, -1.2313,  ..., -0.8585,  1.6570,  2.5556],\n",
      "          [ 0.4820, -0.4635,  0.3191,  ..., -0.6811,  0.1392, -0.4434],\n",
      "          [ 0.1668, -1.1097, -0.8286,  ..., -0.9495,  1.5589, -0.0580],\n",
      "          ...,\n",
      "          [-0.3971, -0.6843, -0.8557,  ..., -0.5025, -0.1033,  0.4068],\n",
      "          [-1.0900,  0.6832,  1.1090,  ..., -1.6403, -0.0437,  0.4522],\n",
      "          [-0.5619,  0.5400,  0.7851,  ..., -1.5358, -0.6291, -0.3296]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.3044,  0.7540, -1.5177,  ...,  0.6235, -0.0899,  3.0908],\n",
       "          [ 0.5901, -1.4152, -0.2312,  ..., -1.8907,  1.9177,  0.5691],\n",
       "          [-0.3886, -1.4381, -0.8307,  ..., -0.4119, -0.5074,  1.1393],\n",
       "          ...,\n",
       "          [-0.4840, -1.0250, -0.4982,  ...,  0.6701,  0.2114,  1.4567],\n",
       "          [ 1.4101,  0.9289,  0.6544,  ...,  2.7610,  0.2670, -0.0039],\n",
       "          [ 2.0325, -0.2024, -2.0813,  ...,  1.2517,  1.5438,  0.1431]],\n",
       "\n",
       "         [[ 0.6788, -0.6160, -0.0460,  ...,  1.2763, -0.9281,  0.4504],\n",
       "          [-1.5570, -0.1272,  2.0995,  ...,  0.5402,  0.5966,  0.8183],\n",
       "          [ 1.2140,  2.6829, -0.4258,  ...,  0.5324, -1.4423, -1.2142],\n",
       "          ...,\n",
       "          [-0.4453, -0.6367,  1.1478,  ..., -1.4535, -2.4058,  0.4512],\n",
       "          [-0.7411, -0.2841, -0.1344,  ...,  0.9410, -0.1128, -0.9692],\n",
       "          [-1.0666, -0.2804, -0.9853,  ..., -0.4616, -0.9477, -0.3935]],\n",
       "\n",
       "         [[ 0.5055, -0.6264,  0.4532,  ...,  0.8404,  1.7172,  0.7068],\n",
       "          [-0.1991,  1.0388,  1.0157,  ..., -1.3901, -1.8518, -0.5196],\n",
       "          [-0.6752, -1.1405,  0.5670,  ...,  1.0066,  0.4512,  0.1531],\n",
       "          ...,\n",
       "          [-0.6310, -0.1000,  0.3842,  ..., -0.8271, -0.5949,  1.2789],\n",
       "          [-0.2688,  0.5778, -0.0246,  ..., -0.1167,  1.1109,  0.6747],\n",
       "          [ 1.5399,  0.3914, -1.5289,  ..., -0.4791, -0.7300,  0.4437]]],\n",
       "\n",
       "\n",
       "        [[[-2.3989,  0.1256,  0.8555,  ...,  0.5750, -1.0436,  0.4934],\n",
       "          [ 0.7335,  0.3081,  1.0395,  ...,  0.0177,  1.0942,  0.6037],\n",
       "          [ 2.0948,  1.5887, -0.1003,  ...,  0.0204,  1.1576, -0.1042],\n",
       "          ...,\n",
       "          [-1.0514,  0.6295, -0.8055,  ..., -2.5075, -0.9646, -0.1401],\n",
       "          [-0.3995,  0.4450, -1.3803,  ..., -1.4225,  1.5039,  0.1247],\n",
       "          [-0.1091,  0.4499,  0.7655,  ...,  0.6336, -0.0476,  2.3477]],\n",
       "\n",
       "         [[ 1.8175,  0.9484,  0.3751,  ..., -0.8077,  1.0218,  1.3239],\n",
       "          [-2.1371, -0.9305,  1.5929,  ..., -0.9087, -0.5195,  0.7040],\n",
       "          [ 0.7619, -0.8183,  1.0030,  ...,  0.1921,  1.0271, -0.2522],\n",
       "          ...,\n",
       "          [-1.0584, -0.1344, -0.9631,  ...,  0.9484,  2.2136, -0.5076],\n",
       "          [-1.5460,  0.6247,  0.1021,  ..., -1.4688, -0.2744, -0.1154],\n",
       "          [ 0.1468, -0.2053, -2.0332,  ..., -0.9090, -0.0336,  0.9345]],\n",
       "\n",
       "         [[ 1.9661, -0.0551, -1.2313,  ..., -0.8585,  1.6570,  2.5556],\n",
       "          [ 0.4820, -0.4635,  0.3191,  ..., -0.6811,  0.1392, -0.4434],\n",
       "          [ 0.1668, -1.1097, -0.8286,  ..., -0.9495,  1.5589, -0.0580],\n",
       "          ...,\n",
       "          [-0.3971, -0.6843, -0.8557,  ..., -0.5025, -0.1033,  0.4068],\n",
       "          [-1.0900,  0.6832,  1.1090,  ..., -1.6403, -0.0437,  0.4522],\n",
       "          [-0.5619,  0.5400,  0.7851,  ..., -1.5358, -0.6291, -0.3296]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd = torch.randn(2, 3, 224, 224)\n",
    "print(rnd)\n",
    "nn.Parameter(rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outstanding-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4, 2])\n",
      "torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "rnd = torch.randn(2, 8, 4, 2)\n",
    "print(rnd.shape)\n",
    "rnd = rnd.mean(dim = 1)\n",
    "print(rnd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prerequisite-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8069],\n",
      "        [ 0.1675],\n",
      "        [ 0.8866],\n",
      "        [-1.6333],\n",
      "        [-1.2031],\n",
      "        [-1.3319],\n",
      "        [ 0.4917],\n",
      "        [ 0.2780]])\n",
      "tensor([ 0.8069,  0.1675,  0.8866, -1.6333, -1.2031, -1.3319,  0.4917,  0.2780])\n",
      "torch.return_types.sort(\n",
      "values=tensor([ 0.8866,  0.8069,  0.4917,  0.2780,  0.1675, -1.2031, -1.3319, -1.6333]),\n",
      "indices=tensor([2, 0, 6, 7, 1, 4, 5, 3]))\n"
     ]
    }
   ],
   "source": [
    "rnd = torch.randn(8, 1)\n",
    "print(rnd)\n",
    "rnd = rnd.squeeze(1)\n",
    "print(rnd)\n",
    "rnd = rnd.sort(dim = 0, descending = True)\n",
    "print(rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stopped-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dleng = [5, 9]\n",
    "for t in range(max(dleng)) : \n",
    "    batch_size_t = sum([l > t for l in dleng])\n",
    "    print(batch_size_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "powerful-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190,\n",
       "        190, 190], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_tokens = torch.ones(16, dtype = torch.long).to(DEVICE) * tokenizer.stoi[\"<sos>\"]\n",
    "start_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-stations",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prospective-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred) : \n",
    "    scores = []\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred) : \n",
    "        score = Levenshtein.distance(true, pred)\n",
    "        scores.append(score)\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "manufactured-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "criminal-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed = 0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faced-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object) : \n",
    "    def __init__(self) : \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self) : \n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n = 1) : \n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "stainless-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "published-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bms_collate(batch):\n",
    "    imgs, labels, label_lengths = [], [], []\n",
    "    for data_point in batch:\n",
    "        imgs.append(data_point[0])\n",
    "        labels.append(data_point[1])\n",
    "        label_lengths.append(data_point[2])\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.stoi[\"<pad>\"])\n",
    "    return torch.stack(imgs), labels, torch.stack(label_lengths).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-analysis",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "referenced-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\torch37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    484838\n",
      "1    484837\n",
      "2    484837\n",
      "3    484837\n",
      "4    484837\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['InChI_length'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "    \n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-prototype",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "otherwise-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch,\n",
    "             encoder_scheduler, decoder_scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    for step, (images, labels, label_lengths) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        features = encoder(images)\n",
    "        \n",
    "        predictions, caps_sorted, decode_lengths, alphas, sort_ind = decoder(features, labels, label_lengths)\n",
    "        targets = caps_sorted[:, 1:]\n",
    "        predictions = pack_padded_sequence(predictions, decode_lengths, batch_first=True).data\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "        \n",
    "        loss = criterion(predictions, targets)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_grad_norm = torch.nn.utils.clip_grad_norm_(encoder.parameters(), CFG.max_grad_norm)\n",
    "        decoder_grad_norm = torch.nn.utils.clip_grad_norm_(decoder.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Encoder Grad: {encoder_grad_norm:.4f}  '\n",
    "                  'Decoder Grad: {decoder_grad_norm:.4f}  '\n",
    "                  #'Encoder LR: {encoder_lr:.6f}  '\n",
    "                  #'Decoder LR: {decoder_lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   encoder_grad_norm=encoder_grad_norm,\n",
    "                   decoder_grad_norm=decoder_grad_norm,\n",
    "                   #encoder_lr=encoder_scheduler.get_lr()[0],\n",
    "                   #decoder_lr=decoder_scheduler.get_lr()[0],\n",
    "                   ))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "exclusive-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, device) : \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    text_preds = []\n",
    "    start = end = time.time()\n",
    "    \n",
    "    for step, (images) in enumerate(valid_loader) : \n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad() : \n",
    "            features = encoder(images)\n",
    "            predictions = decoder.predict(features, CFG.max_len, tokenizer)\n",
    "        \n",
    "        predicted_sequence = torch.argmax(predictions.detach().cpu(), -1).numpy()\n",
    "        _text_preds = tokenizer.predict_captions(predicted_sequence)\n",
    "        text_preds.append(_text_preds)\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1) :\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "            \n",
    "    text_preds = np.concatenate(text_preds)\n",
    "    return text_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "handy-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(folds, fold) :\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    \n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop = True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop = True)\n",
    "    valid_labels = valid_folds['InChI'].values\n",
    "    \n",
    "    train_dataset = TrainDataset(train_folds, tokenizer, transform = Transform)\n",
    "    valid_dataset = TestDataset(valid_folds, Transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                             batch_size = CFG.batch_size,\n",
    "                             shuffle = True,\n",
    "                             num_workers = CFG.num_workers,\n",
    "                             pin_memory = True,\n",
    "                             drop_last = True,\n",
    "                             collate_fn = bms_collate)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                             batch_size = CFG.batch_size,\n",
    "                             shuffle = False,\n",
    "                             num_workers = CFG.num_workers,\n",
    "                             pin_memory = True,\n",
    "                             drop_last = False)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "    \n",
    "    encoder = Encoder(CFG.model_name, pretrained = True)\n",
    "    encoder.to(DEVICE)\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr = CFG.encoder_lr,\n",
    "                             weight_decay = CFG.weight_decay, amsgrad = False)\n",
    "    encoder_scheduler = get_scheduler(encoder_optimizer)\n",
    "    \n",
    "    decoder = DecoderWithAttention(attention_dim = CFG.attention_dim,\n",
    "                                  embed_dim = CFG.embed_dim,\n",
    "                                  decoder_dim = CFG.decoder_dim,\n",
    "                                  vocab_size = len(tokenizer),\n",
    "                                  dropout = CFG.dropout,\n",
    "                                  device = DEVICE)\n",
    "    decoder.to(DEVICE)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr = CFG.decoder_lr,\n",
    "                            weight_decay = CFG.weight_decay, amsgrad = False)\n",
    "    decoder_scheduler = get_scheduler(decoder_optimizer)\n",
    "    \n",
    "    # Loop\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.stoi[\"<pad>\"])\n",
    "    \n",
    "    best_score = np.inf\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs) : \n",
    "        start_time = time.time()\n",
    "        \n",
    "        #train\n",
    "        avg_loss = train_fn(train_loader, encoder, decoder, criterion,\n",
    "                           encoder_optimizer, decoder_optimizer, epoch, encoder_scheduler, decoder_scheduler,\n",
    "                            DEVICE)\n",
    "        \n",
    "        # eval\n",
    "        text_preds = valid_fn(valid_loader, encoder, decoder, tokenizer,\n",
    "                             criterion, DEVICE)\n",
    "        text_preds = [f\"InChI=1S/{text}\" for text in text_preds]\n",
    "        LOGGER.info(f\"labels: {valid_labels[:5]}\")\n",
    "        LOGGER.info(f\"preds: {text_preds[:5]}\")\n",
    "        \n",
    "        # scoreing\n",
    "        score = get_score(valid_labels, text_preds)\n",
    "        \n",
    "        if isinstance(encoder_scheduler, ReduceLROnPlateau):\n",
    "            encoder_scheduler.step(score)\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingLR):\n",
    "            encoder_scheduler.step()\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            encoder_scheduler.step()\n",
    "            \n",
    "        if isinstance(decoder_scheduler, ReduceLROnPlateau):\n",
    "            decoder_scheduler.step(score)\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingLR):\n",
    "            decoder_scheduler.step()\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            decoder_scheduler.step()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'encoder': encoder.state_dict(), \n",
    "                        'encoder_optimizer': encoder_optimizer.state_dict(), \n",
    "                        #'encoder_scheduler': encoder_scheduler.state_dict(), \n",
    "                        'decoder': decoder.state_dict(), \n",
    "                        'decoder_optimizer': decoder_optimizer.state_dict(), \n",
    "                        #'decoder_scheduler': decoder_scheduler.state_dict(), \n",
    "                        'text_preds': text_preds,\n",
    "                       },\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "opposed-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() : \n",
    "    if CFG.train : \n",
    "        oof_df = pd.DataFrame()\n",
    "        \n",
    "        for fold in range(CFG.n_fold) : \n",
    "            if fold in CFG.trn_fold : \n",
    "                train_loop(folds, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "genuine-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/121209] Data 0.177 (0.177) Elapsed 0m 0s (remain 989m 28s) Loss: 5.2585(5.2585) Encoder Grad: 1.7430  Decoder Grad: 1.0495  \n",
      "Epoch: [1][1000/121209] Data 0.095 (0.094) Elapsed 8m 9s (remain 980m 25s) Loss: 1.4970(1.7950) Encoder Grad: 0.4348  Decoder Grad: 0.6042  \n",
      "Epoch: [1][2000/121209] Data 0.090 (0.097) Elapsed 17m 11s (remain 1023m 59s) Loss: 1.1157(1.5647) Encoder Grad: 0.4309  Decoder Grad: 0.7118  \n",
      "Epoch: [1][3000/121209] Data 0.091 (0.098) Elapsed 26m 1s (remain 1025m 11s) Loss: 1.0913(1.4305) Encoder Grad: 0.4743  Decoder Grad: 0.7057  \n",
      "Epoch: [1][4000/121209] Data 0.087 (0.097) Elapsed 34m 32s (remain 1011m 57s) Loss: 1.0540(1.3330) Encoder Grad: 0.8154  Decoder Grad: 0.6963  \n",
      "Epoch: [1][5000/121209] Data 0.090 (0.096) Elapsed 42m 49s (remain 995m 10s) Loss: 0.8352(1.2563) Encoder Grad: 0.5059  Decoder Grad: 0.5810  \n",
      "Epoch: [1][6000/121209] Data 0.084 (0.094) Elapsed 50m 35s (remain 971m 20s) Loss: 0.7546(1.1937) Encoder Grad: 0.6448  Decoder Grad: 0.6096  \n",
      "Epoch: [1][7000/121209] Data 0.089 (0.093) Elapsed 58m 22s (remain 952m 20s) Loss: 0.9307(1.1408) Encoder Grad: 0.5452  Decoder Grad: 0.6602  \n",
      "Epoch: [1][8000/121209] Data 0.089 (0.092) Elapsed 66m 9s (remain 936m 2s) Loss: 0.6753(1.0949) Encoder Grad: 0.5653  Decoder Grad: 0.5640  \n",
      "Epoch: [1][9000/121209] Data 0.081 (0.091) Elapsed 73m 56s (remain 921m 43s) Loss: 0.6561(1.0545) Encoder Grad: 1.1900  Decoder Grad: 0.9188  \n",
      "Epoch: [1][10000/121209] Data 0.084 (0.090) Elapsed 81m 41s (remain 908m 24s) Loss: 0.7314(1.0183) Encoder Grad: 0.6971  Decoder Grad: 0.6852  \n",
      "Epoch: [1][11000/121209] Data 0.084 (0.090) Elapsed 89m 29s (remain 896m 28s) Loss: 0.5495(0.9861) Encoder Grad: 0.6604  Decoder Grad: 0.6361  \n",
      "Epoch: [1][12000/121209] Data 0.079 (0.089) Elapsed 97m 13s (remain 884m 42s) Loss: 0.5633(0.9569) Encoder Grad: 0.5168  Decoder Grad: 0.4977  \n",
      "Epoch: [1][13000/121209] Data 0.089 (0.089) Elapsed 104m 58s (remain 873m 46s) Loss: 0.6497(0.9307) Encoder Grad: 0.5686  Decoder Grad: 0.5722  \n",
      "Epoch: [1][14000/121209] Data 0.076 (0.089) Elapsed 112m 42s (remain 862m 59s) Loss: 0.5331(0.9066) Encoder Grad: 0.6695  Decoder Grad: 0.6505  \n",
      "Epoch: [1][15000/121209] Data 0.087 (0.089) Elapsed 120m 27s (remain 852m 48s) Loss: 0.5419(0.8845) Encoder Grad: 0.6983  Decoder Grad: 0.5946  \n",
      "Epoch: [1][16000/121209] Data 0.088 (0.088) Elapsed 128m 12s (remain 842m 58s) Loss: 0.5393(0.8639) Encoder Grad: 0.5323  Decoder Grad: 0.5917  \n",
      "Epoch: [1][17000/121209] Data 0.079 (0.088) Elapsed 136m 0s (remain 833m 41s) Loss: 0.5716(0.8453) Encoder Grad: 0.6619  Decoder Grad: 0.5682  \n",
      "Epoch: [1][18000/121209] Data 0.080 (0.088) Elapsed 143m 46s (remain 824m 21s) Loss: 0.5433(0.8277) Encoder Grad: 0.7446  Decoder Grad: 0.6261  \n",
      "Epoch: [1][19000/121209] Data 0.089 (0.088) Elapsed 151m 30s (remain 814m 57s) Loss: 0.4430(0.8112) Encoder Grad: 0.6122  Decoder Grad: 0.5701  \n",
      "Epoch: [1][20000/121209] Data 0.083 (0.088) Elapsed 159m 16s (remain 805m 56s) Loss: 0.5405(0.7958) Encoder Grad: 0.7680  Decoder Grad: 0.6329  \n",
      "Epoch: [1][21000/121209] Data 0.089 (0.087) Elapsed 166m 59s (remain 796m 47s) Loss: 0.4814(0.7811) Encoder Grad: 0.6089  Decoder Grad: 0.5326  \n",
      "Epoch: [1][22000/121209] Data 0.084 (0.087) Elapsed 174m 43s (remain 787m 51s) Loss: 0.4453(0.7673) Encoder Grad: 0.6756  Decoder Grad: 0.6224  \n",
      "Epoch: [1][23000/121209] Data 0.079 (0.087) Elapsed 182m 27s (remain 779m 3s) Loss: 0.4156(0.7543) Encoder Grad: 1.0570  Decoder Grad: 0.6155  \n",
      "Epoch: [1][24000/121209] Data 0.087 (0.087) Elapsed 190m 12s (remain 770m 21s) Loss: 0.4028(0.7420) Encoder Grad: 0.7678  Decoder Grad: 0.6897  \n",
      "Epoch: [1][25000/121209] Data 0.077 (0.087) Elapsed 197m 55s (remain 761m 37s) Loss: 0.4318(0.7302) Encoder Grad: 0.7881  Decoder Grad: 0.5825  \n",
      "Epoch: [1][26000/121209] Data 0.086 (0.087) Elapsed 205m 40s (remain 753m 8s) Loss: 0.5293(0.7190) Encoder Grad: 0.9726  Decoder Grad: 0.5639  \n",
      "Epoch: [1][27000/121209] Data 0.087 (0.087) Elapsed 213m 29s (remain 744m 54s) Loss: 0.5262(0.7084) Encoder Grad: 0.7356  Decoder Grad: 0.5888  \n",
      "Epoch: [1][28000/121209] Data 0.085 (0.087) Elapsed 221m 13s (remain 736m 24s) Loss: 0.3826(0.6982) Encoder Grad: 0.7772  Decoder Grad: 0.5338  \n",
      "Epoch: [1][29000/121209] Data 0.084 (0.087) Elapsed 228m 57s (remain 727m 58s) Loss: 0.3169(0.6886) Encoder Grad: 0.6672  Decoder Grad: 0.5256  \n",
      "Epoch: [1][30000/121209] Data 0.082 (0.087) Elapsed 236m 42s (remain 719m 36s) Loss: 0.3202(0.6792) Encoder Grad: 0.6420  Decoder Grad: 0.6335  \n",
      "Epoch: [1][31000/121209] Data 0.088 (0.086) Elapsed 244m 28s (remain 711m 23s) Loss: 0.4164(0.6703) Encoder Grad: 0.6579  Decoder Grad: 0.7089  \n",
      "Epoch: [1][32000/121209] Data 0.085 (0.086) Elapsed 252m 16s (remain 703m 15s) Loss: 0.2645(0.6617) Encoder Grad: 0.5119  Decoder Grad: 0.4643  \n",
      "Epoch: [1][33000/121209] Data 0.075 (0.086) Elapsed 260m 3s (remain 695m 5s) Loss: 0.4668(0.6535) Encoder Grad: 0.9707  Decoder Grad: 0.7068  \n",
      "Epoch: [1][34000/121209] Data 0.083 (0.086) Elapsed 267m 45s (remain 686m 46s) Loss: 0.3660(0.6454) Encoder Grad: 0.7549  Decoder Grad: 0.5135  \n",
      "Epoch: [1][35000/121209] Data 0.088 (0.086) Elapsed 275m 32s (remain 678m 39s) Loss: 0.3664(0.6378) Encoder Grad: 0.6996  Decoder Grad: 0.6559  \n",
      "Epoch: [1][36000/121209] Data 0.084 (0.086) Elapsed 283m 14s (remain 670m 21s) Loss: 0.3190(0.6304) Encoder Grad: 0.6024  Decoder Grad: 0.4755  \n",
      "Epoch: [1][37000/121209] Data 0.088 (0.086) Elapsed 290m 59s (remain 662m 13s) Loss: 0.4269(0.6232) Encoder Grad: 0.5301  Decoder Grad: 0.5244  \n",
      "Epoch: [1][38000/121209] Data 0.087 (0.086) Elapsed 298m 42s (remain 654m 2s) Loss: 0.3722(0.6163) Encoder Grad: 0.6256  Decoder Grad: 0.4876  \n",
      "Epoch: [1][39000/121209] Data 0.077 (0.086) Elapsed 306m 26s (remain 645m 55s) Loss: 0.3464(0.6097) Encoder Grad: 0.5824  Decoder Grad: 0.5006  \n",
      "Epoch: [1][40000/121209] Data 0.088 (0.086) Elapsed 314m 10s (remain 637m 48s) Loss: 0.3307(0.6032) Encoder Grad: 0.6890  Decoder Grad: 0.4580  \n",
      "Epoch: [1][41000/121209] Data 0.086 (0.086) Elapsed 321m 53s (remain 629m 41s) Loss: 0.2485(0.5970) Encoder Grad: 0.5754  Decoder Grad: 0.4745  \n",
      "Epoch: [1][42000/121209] Data 0.081 (0.086) Elapsed 329m 36s (remain 621m 36s) Loss: 0.3212(0.5909) Encoder Grad: 0.6391  Decoder Grad: 0.5486  \n",
      "Epoch: [1][43000/121209] Data 0.087 (0.086) Elapsed 337m 20s (remain 613m 31s) Loss: 0.3095(0.5852) Encoder Grad: 0.7972  Decoder Grad: 0.5538  \n",
      "Epoch: [1][44000/121209] Data 0.082 (0.086) Elapsed 345m 3s (remain 605m 28s) Loss: 0.3302(0.5796) Encoder Grad: 0.7013  Decoder Grad: 0.5154  \n",
      "Epoch: [1][45000/121209] Data 0.083 (0.086) Elapsed 352m 50s (remain 597m 31s) Loss: 0.2174(0.5741) Encoder Grad: 0.4235  Decoder Grad: 0.3963  \n",
      "Epoch: [1][46000/121209] Data 0.083 (0.086) Elapsed 360m 38s (remain 589m 36s) Loss: 0.2854(0.5688) Encoder Grad: 0.7278  Decoder Grad: 0.5053  \n",
      "Epoch: [1][47000/121209] Data 0.087 (0.086) Elapsed 368m 24s (remain 581m 39s) Loss: 0.2909(0.5637) Encoder Grad: 1.1085  Decoder Grad: 0.5523  \n",
      "Epoch: [1][48000/121209] Data 0.082 (0.086) Elapsed 376m 9s (remain 573m 42s) Loss: 0.2709(0.5586) Encoder Grad: 0.5766  Decoder Grad: 0.4145  \n",
      "Epoch: [1][49000/121209] Data 0.083 (0.086) Elapsed 383m 54s (remain 565m 44s) Loss: 0.3017(0.5537) Encoder Grad: 0.5492  Decoder Grad: 0.4471  \n",
      "Epoch: [1][50000/121209] Data 0.086 (0.086) Elapsed 391m 39s (remain 557m 46s) Loss: 0.3086(0.5490) Encoder Grad: 0.5048  Decoder Grad: 0.4543  \n",
      "Epoch: [1][51000/121209] Data 0.082 (0.086) Elapsed 399m 27s (remain 549m 53s) Loss: 0.3678(0.5444) Encoder Grad: 0.4769  Decoder Grad: 0.3841  \n",
      "Epoch: [1][52000/121209] Data 0.090 (0.086) Elapsed 407m 14s (remain 541m 59s) Loss: 0.4012(0.5400) Encoder Grad: 0.6074  Decoder Grad: 0.5364  \n",
      "Epoch: [1][53000/121209] Data 0.085 (0.086) Elapsed 414m 58s (remain 534m 1s) Loss: 0.3750(0.5356) Encoder Grad: 0.6883  Decoder Grad: 0.6167  \n",
      "Epoch: [1][54000/121209] Data 0.090 (0.086) Elapsed 422m 46s (remain 526m 10s) Loss: 0.3462(0.5313) Encoder Grad: 0.5358  Decoder Grad: 0.4021  \n",
      "Epoch: [1][55000/121209] Data 0.085 (0.086) Elapsed 430m 32s (remain 518m 16s) Loss: 0.2677(0.5271) Encoder Grad: 0.5264  Decoder Grad: 0.4359  \n",
      "Epoch: [1][56000/121209] Data 0.083 (0.086) Elapsed 438m 21s (remain 510m 25s) Loss: 0.2509(0.5231) Encoder Grad: 0.6124  Decoder Grad: 0.5044  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][57000/121209] Data 0.079 (0.086) Elapsed 446m 8s (remain 502m 32s) Loss: 0.2522(0.5192) Encoder Grad: 0.4551  Decoder Grad: 0.4288  \n",
      "Epoch: [1][58000/121209] Data 0.089 (0.086) Elapsed 453m 55s (remain 494m 40s) Loss: 0.2936(0.5153) Encoder Grad: 0.7443  Decoder Grad: 0.5211  \n",
      "Epoch: [1][59000/121209] Data 0.085 (0.086) Elapsed 461m 43s (remain 486m 49s) Loss: 0.3562(0.5116) Encoder Grad: 0.7737  Decoder Grad: 0.5890  \n",
      "Epoch: [1][60000/121209] Data 0.088 (0.086) Elapsed 469m 28s (remain 478m 54s) Loss: 0.2590(0.5079) Encoder Grad: 0.7402  Decoder Grad: 0.4896  \n",
      "Epoch: [1][61000/121209] Data 0.079 (0.086) Elapsed 477m 13s (remain 471m 1s) Loss: 0.3171(0.5043) Encoder Grad: 0.6746  Decoder Grad: 0.4113  \n",
      "Epoch: [1][62000/121209] Data 0.083 (0.086) Elapsed 484m 59s (remain 463m 8s) Loss: 0.3103(0.5007) Encoder Grad: 0.5122  Decoder Grad: 0.4014  \n",
      "Epoch: [1][63000/121209] Data 0.084 (0.086) Elapsed 492m 46s (remain 455m 17s) Loss: 0.2913(0.4973) Encoder Grad: 0.6141  Decoder Grad: 0.4816  \n",
      "Epoch: [1][64000/121209] Data 0.084 (0.086) Elapsed 500m 34s (remain 447m 26s) Loss: 0.4145(0.4940) Encoder Grad: 1.0042  Decoder Grad: 1.0347  \n",
      "Epoch: [1][65000/121209] Data 0.088 (0.086) Elapsed 508m 21s (remain 439m 35s) Loss: 0.4355(0.4907) Encoder Grad: 0.5956  Decoder Grad: 0.4890  \n",
      "Epoch: [1][66000/121209] Data 0.082 (0.086) Elapsed 516m 8s (remain 431m 44s) Loss: 0.1904(0.4875) Encoder Grad: 0.4065  Decoder Grad: 0.3680  \n",
      "Epoch: [1][67000/121209] Data 0.087 (0.086) Elapsed 523m 55s (remain 423m 53s) Loss: 0.2338(0.4844) Encoder Grad: 0.4219  Decoder Grad: 0.3838  \n",
      "Epoch: [1][68000/121209] Data 0.088 (0.086) Elapsed 531m 42s (remain 416m 2s) Loss: 0.3682(0.4813) Encoder Grad: 1.0524  Decoder Grad: 0.4244  \n",
      "Epoch: [1][69000/121209] Data 0.088 (0.086) Elapsed 539m 27s (remain 408m 9s) Loss: 0.3692(0.4782) Encoder Grad: 0.4671  Decoder Grad: 0.4729  \n",
      "Epoch: [1][70000/121209] Data 0.088 (0.086) Elapsed 547m 15s (remain 400m 20s) Loss: 0.5089(0.4753) Encoder Grad: 0.6407  Decoder Grad: 0.5597  \n",
      "Epoch: [1][71000/121209] Data 0.086 (0.086) Elapsed 555m 0s (remain 392m 28s) Loss: 0.3313(0.4724) Encoder Grad: 0.9266  Decoder Grad: 0.5286  \n",
      "Epoch: [1][72000/121209] Data 0.086 (0.086) Elapsed 562m 46s (remain 384m 37s) Loss: 0.2736(0.4695) Encoder Grad: 0.6084  Decoder Grad: 0.4756  \n",
      "Epoch: [1][73000/121209] Data 0.078 (0.086) Elapsed 570m 32s (remain 376m 46s) Loss: 0.2611(0.4667) Encoder Grad: 0.6327  Decoder Grad: 0.3967  \n",
      "Epoch: [1][74000/121209] Data 0.083 (0.086) Elapsed 578m 16s (remain 368m 53s) Loss: 0.2564(0.4639) Encoder Grad: 0.5947  Decoder Grad: 0.3676  \n",
      "Epoch: [1][75000/121209] Data 0.083 (0.086) Elapsed 586m 0s (remain 361m 2s) Loss: 0.1725(0.4612) Encoder Grad: 0.4884  Decoder Grad: 0.5147  \n",
      "Epoch: [1][76000/121209] Data 0.089 (0.086) Elapsed 593m 45s (remain 353m 11s) Loss: 0.2316(0.4585) Encoder Grad: 0.3887  Decoder Grad: 0.3498  \n",
      "Epoch: [1][77000/121209] Data 0.105 (0.086) Elapsed 601m 35s (remain 345m 23s) Loss: 0.2280(0.4559) Encoder Grad: 0.6528  Decoder Grad: 0.5443  \n",
      "Epoch: [1][78000/121209] Data 0.098 (0.086) Elapsed 609m 52s (remain 337m 50s) Loss: 0.3223(0.4534) Encoder Grad: 0.4962  Decoder Grad: 0.4360  \n",
      "Epoch: [1][79000/121209] Data 0.094 (0.086) Elapsed 617m 53s (remain 330m 7s) Loss: 0.1905(0.4509) Encoder Grad: 0.5749  Decoder Grad: 0.3535  \n",
      "Epoch: [1][80000/121209] Data 0.083 (0.086) Elapsed 625m 47s (remain 322m 20s) Loss: 0.1848(0.4485) Encoder Grad: 0.4077  Decoder Grad: 0.3166  \n",
      "Epoch: [1][81000/121209] Data 0.086 (0.086) Elapsed 633m 33s (remain 314m 29s) Loss: 0.2977(0.4460) Encoder Grad: 1.0099  Decoder Grad: 0.5047  \n",
      "Epoch: [1][82000/121209] Data 0.084 (0.086) Elapsed 641m 21s (remain 306m 39s) Loss: 0.2798(0.4436) Encoder Grad: 0.6620  Decoder Grad: 0.4325  \n",
      "Epoch: [1][83000/121209] Data 0.086 (0.086) Elapsed 649m 11s (remain 298m 50s) Loss: 0.3404(0.4413) Encoder Grad: 0.4703  Decoder Grad: 0.4571  \n",
      "Epoch: [1][84000/121209] Data 0.081 (0.086) Elapsed 657m 1s (remain 291m 1s) Loss: 0.3020(0.4390) Encoder Grad: 0.7061  Decoder Grad: 0.4347  \n",
      "Epoch: [1][85000/121209] Data 0.086 (0.086) Elapsed 664m 59s (remain 283m 16s) Loss: 0.3032(0.4367) Encoder Grad: 0.5371  Decoder Grad: 0.4758  \n",
      "Epoch: [1][86000/121209] Data 0.088 (0.086) Elapsed 672m 56s (remain 275m 29s) Loss: 0.1735(0.4345) Encoder Grad: 0.4433  Decoder Grad: 0.3738  \n",
      "Epoch: [1][87000/121209] Data 0.086 (0.086) Elapsed 680m 47s (remain 267m 40s) Loss: 0.1909(0.4323) Encoder Grad: 0.5182  Decoder Grad: 0.4158  \n",
      "Epoch: [1][88000/121209] Data 0.086 (0.086) Elapsed 688m 37s (remain 259m 51s) Loss: 0.2696(0.4301) Encoder Grad: 0.5989  Decoder Grad: 0.5190  \n",
      "Epoch: [1][89000/121209] Data 0.084 (0.086) Elapsed 696m 21s (remain 252m 0s) Loss: 0.1824(0.4280) Encoder Grad: 0.3466  Decoder Grad: 0.3195  \n",
      "Epoch: [1][90000/121209] Data 0.085 (0.086) Elapsed 704m 23s (remain 244m 15s) Loss: 0.2863(0.4259) Encoder Grad: 0.5413  Decoder Grad: 0.5248  \n",
      "Epoch: [1][91000/121209] Data 0.086 (0.086) Elapsed 713m 10s (remain 236m 44s) Loss: 0.1743(0.4239) Encoder Grad: 0.4466  Decoder Grad: 0.4562  \n",
      "Epoch: [1][92000/121209] Data 0.093 (0.086) Elapsed 721m 52s (remain 229m 10s) Loss: 0.2504(0.4219) Encoder Grad: 0.4892  Decoder Grad: 0.3942  \n",
      "Epoch: [1][93000/121209] Data 0.089 (0.086) Elapsed 730m 26s (remain 221m 32s) Loss: 0.3551(0.4199) Encoder Grad: 0.6160  Decoder Grad: 0.4885  \n",
      "Epoch: [1][94000/121209] Data 0.144 (0.086) Elapsed 739m 10s (remain 213m 56s) Loss: 0.2815(0.4180) Encoder Grad: 0.4673  Decoder Grad: 0.3430  \n",
      "Epoch: [1][95000/121209] Data 0.109 (0.087) Elapsed 749m 18s (remain 206m 42s) Loss: 0.1806(0.4160) Encoder Grad: 1.0742  Decoder Grad: 0.3817  \n",
      "Epoch: [1][96000/121209] Data 0.102 (0.087) Elapsed 759m 34s (remain 199m 26s) Loss: 0.2280(0.4141) Encoder Grad: 0.9797  Decoder Grad: 0.5556  \n",
      "Epoch: [1][97000/121209] Data 0.092 (0.087) Elapsed 769m 51s (remain 192m 7s) Loss: 0.1410(0.4122) Encoder Grad: 0.5750  Decoder Grad: 0.5297  \n",
      "Epoch: [1][98000/121209] Data 0.099 (0.088) Elapsed 778m 49s (remain 184m 26s) Loss: 0.3001(0.4104) Encoder Grad: 0.5706  Decoder Grad: 0.4077  \n",
      "Epoch: [1][99000/121209] Data 0.099 (0.088) Elapsed 789m 13s (remain 177m 2s) Loss: 0.2213(0.4086) Encoder Grad: 0.5736  Decoder Grad: 0.4580  \n",
      "Epoch: [1][100000/121209] Data 0.109 (0.088) Elapsed 799m 40s (remain 169m 35s) Loss: 0.1996(0.4067) Encoder Grad: 0.3977  Decoder Grad: 0.3791  \n",
      "Epoch: [1][101000/121209] Data 0.095 (0.088) Elapsed 809m 49s (remain 162m 1s) Loss: 0.2670(0.4050) Encoder Grad: 0.5147  Decoder Grad: 0.4637  \n",
      "Epoch: [1][102000/121209] Data 0.101 (0.088) Elapsed 819m 32s (remain 154m 19s) Loss: 0.1994(0.4032) Encoder Grad: 0.3964  Decoder Grad: 0.4198  \n",
      "Epoch: [1][103000/121209] Data 0.096 (0.089) Elapsed 829m 26s (remain 146m 37s) Loss: 0.2525(0.4014) Encoder Grad: 1.2166  Decoder Grad: 0.7602  \n",
      "Epoch: [1][104000/121209] Data 0.106 (0.089) Elapsed 839m 38s (remain 138m 55s) Loss: 0.3605(0.3998) Encoder Grad: 0.6132  Decoder Grad: 0.5214  \n",
      "Epoch: [1][105000/121209] Data 0.096 (0.089) Elapsed 849m 25s (remain 131m 7s) Loss: 0.1715(0.3981) Encoder Grad: 0.4291  Decoder Grad: 0.3948  \n",
      "Epoch: [1][106000/121209] Data 0.092 (0.089) Elapsed 859m 28s (remain 123m 18s) Loss: 0.2959(0.3964) Encoder Grad: 0.5219  Decoder Grad: 0.4158  \n",
      "Epoch: [1][107000/121209] Data 0.102 (0.089) Elapsed 869m 7s (remain 115m 24s) Loss: 0.1591(0.3948) Encoder Grad: 2.6048  Decoder Grad: 0.5031  \n",
      "Epoch: [1][108000/121209] Data 0.096 (0.089) Elapsed 878m 51s (remain 107m 28s) Loss: 0.1428(0.3932) Encoder Grad: 0.4892  Decoder Grad: 0.4206  \n",
      "Epoch: [1][109000/121209] Data 0.096 (0.089) Elapsed 888m 30s (remain 99m 30s) Loss: 0.2348(0.3916) Encoder Grad: 0.6867  Decoder Grad: 0.3534  \n",
      "Epoch: [1][110000/121209] Data 0.105 (0.090) Elapsed 897m 49s (remain 91m 28s) Loss: 0.2320(0.3900) Encoder Grad: 0.6140  Decoder Grad: 0.4906  \n",
      "Epoch: [1][111000/121209] Data 0.094 (0.090) Elapsed 907m 20s (remain 83m 26s) Loss: 0.1149(0.3885) Encoder Grad: 0.3855  Decoder Grad: 0.4376  \n",
      "Epoch: [1][112000/121209] Data 0.107 (0.090) Elapsed 916m 56s (remain 75m 23s) Loss: 0.1308(0.3869) Encoder Grad: 0.6557  Decoder Grad: 0.3060  \n",
      "Epoch: [1][113000/121209] Data 0.106 (0.090) Elapsed 926m 59s (remain 67m 20s) Loss: 0.2417(0.3854) Encoder Grad: 0.6356  Decoder Grad: 0.4365  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][114000/121209] Data 0.095 (0.090) Elapsed 937m 57s (remain 59m 18s) Loss: 0.1618(0.3839) Encoder Grad: 0.5558  Decoder Grad: 0.4207  \n",
      "Epoch: [1][115000/121209] Data 0.099 (0.090) Elapsed 947m 54s (remain 51m 10s) Loss: 0.3339(0.3824) Encoder Grad: 0.7704  Decoder Grad: 0.3802  \n",
      "Epoch: [1][116000/121209] Data 0.101 (0.090) Elapsed 957m 57s (remain 43m 0s) Loss: 0.1908(0.3810) Encoder Grad: 0.4250  Decoder Grad: 0.3236  \n",
      "Epoch: [1][117000/121209] Data 0.115 (0.091) Elapsed 967m 45s (remain 34m 48s) Loss: 0.1816(0.3795) Encoder Grad: 0.4347  Decoder Grad: 0.4096  \n",
      "Epoch: [1][118000/121209] Data 0.085 (0.091) Elapsed 975m 31s (remain 26m 31s) Loss: 0.1619(0.3781) Encoder Grad: 0.4918  Decoder Grad: 0.3450  \n",
      "Epoch: [1][119000/121209] Data 0.091 (0.091) Elapsed 983m 19s (remain 18m 14s) Loss: 0.2046(0.3767) Encoder Grad: 0.4373  Decoder Grad: 0.4280  \n",
      "Epoch: [1][120000/121209] Data 0.088 (0.091) Elapsed 991m 7s (remain 9m 58s) Loss: 0.2913(0.3753) Encoder Grad: 0.4559  Decoder Grad: 0.5293  \n",
      "Epoch: [1][121000/121209] Data 0.097 (0.091) Elapsed 998m 56s (remain 1m 43s) Loss: 0.3530(0.3739) Encoder Grad: 0.9144  Decoder Grad: 0.4705  \n",
      "Epoch: [1][121208/121209] Data 0.093 (0.091) Elapsed 1000m 32s (remain 0m 0s) Loss: 0.2610(0.3737) Encoder Grad: 3.3755  Decoder Grad: 4.0678  \n",
      "EVAL: [0/30303] Data 0.131 (0.131) Elapsed 0m 0s (remain 192m 11s) \n",
      "EVAL: [1000/30303] Data 0.090 (0.091) Elapsed 6m 8s (remain 179m 32s) \n",
      "EVAL: [2000/30303] Data 0.101 (0.094) Elapsed 13m 4s (remain 184m 51s) \n",
      "EVAL: [3000/30303] Data 0.120 (0.095) Elapsed 19m 49s (remain 180m 20s) \n",
      "EVAL: [4000/30303] Data 0.095 (0.096) Elapsed 26m 38s (remain 175m 7s) \n",
      "EVAL: [5000/30303] Data 0.096 (0.096) Elapsed 33m 34s (remain 169m 49s) \n",
      "EVAL: [6000/30303] Data 0.094 (0.097) Elapsed 40m 22s (remain 163m 29s) \n",
      "EVAL: [7000/30303] Data 0.093 (0.097) Elapsed 47m 6s (remain 156m 46s) \n",
      "EVAL: [8000/30303] Data 0.097 (0.097) Elapsed 53m 50s (remain 150m 5s) \n",
      "EVAL: [9000/30303] Data 0.093 (0.097) Elapsed 60m 37s (remain 143m 29s) \n",
      "EVAL: [10000/30303] Data 0.099 (0.097) Elapsed 67m 26s (remain 136m 53s) \n",
      "EVAL: [11000/30303] Data 0.089 (0.097) Elapsed 73m 58s (remain 129m 47s) \n",
      "EVAL: [12000/30303] Data 0.116 (0.097) Elapsed 81m 59s (remain 125m 3s) \n",
      "EVAL: [13000/30303] Data 0.101 (0.098) Elapsed 101m 31s (remain 135m 6s) \n",
      "EVAL: [14000/30303] Data 0.100 (0.099) Elapsed 131m 41s (remain 153m 20s) \n",
      "EVAL: [15000/30303] Data 0.092 (0.099) Elapsed 140m 54s (remain 143m 43s) \n",
      "EVAL: [16000/30303] Data 0.084 (0.099) Elapsed 150m 29s (remain 134m 30s) \n",
      "EVAL: [17000/30303] Data 0.091 (0.099) Elapsed 159m 30s (remain 124m 48s) \n",
      "EVAL: [18000/30303] Data 0.089 (0.098) Elapsed 165m 9s (remain 112m 52s) \n",
      "EVAL: [19000/30303] Data 0.090 (0.098) Elapsed 171m 38s (remain 102m 5s) \n",
      "EVAL: [20000/30303] Data 0.092 (0.098) Elapsed 177m 50s (remain 91m 36s) \n",
      "EVAL: [21000/30303] Data 0.080 (0.098) Elapsed 183m 58s (remain 81m 29s) \n",
      "EVAL: [22000/30303] Data 0.087 (0.098) Elapsed 189m 42s (remain 71m 35s) \n",
      "EVAL: [23000/30303] Data 0.090 (0.097) Elapsed 204m 38s (remain 64m 58s) \n",
      "EVAL: [24000/30303] Data 0.091 (0.097) Elapsed 219m 9s (remain 57m 32s) \n",
      "EVAL: [25000/30303] Data 0.116 (0.097) Elapsed 235m 30s (remain 49m 56s) \n",
      "EVAL: [26000/30303] Data 0.093 (0.097) Elapsed 247m 34s (remain 40m 57s) \n",
      "EVAL: [27000/30303] Data 0.086 (0.097) Elapsed 253m 16s (remain 30m 58s) \n",
      "EVAL: [28000/30303] Data 0.099 (0.096) Elapsed 258m 59s (remain 21m 17s) \n",
      "EVAL: [29000/30303] Data 0.084 (0.096) Elapsed 264m 29s (remain 11m 52s) \n",
      "EVAL: [30000/30303] Data 0.082 (0.095) Elapsed 269m 53s (remain 2m 43s) \n",
      "EVAL: [30302/30303] Data 0.033 (0.095) Elapsed 271m 30s (remain 0m 0s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: ['InChI=1S/C21H21N5O2S/c1-15-7-8-18(17-5-4-11-22-20(15)17)29(27,28)25-13-9-16(10-14-25)21-24-23-19-6-2-3-12-26(19)21/h2-8,11-12,16H,9-10,13-14H2,1H3'\n",
      " 'InChI=1S/C18H19Cl2NO2/c1-12(2)9-10-23-14-6-3-5-13(11-14)18(22)21-17-15(19)7-4-8-16(17)20/h3-8,11-12H,9-10H2,1-2H3,(H,21,22)'\n",
      " 'InChI=1S/C21H29N5O/c27-21(20(19-8-4-5-9-19)18-6-2-1-3-7-18)25-13-10-24(11-14-25)12-15-26-17-22-16-23-26/h1-3,6-7,16-17,19-20H,4-5,8-15H2'\n",
      " 'InChI=1S/C13H20N2O6/c1-2-20-12(18)9-4-3-5-15(9)13(19)14-6-7-21-10(8-14)11(16)17/h9-10H,2-8H2,1H3,(H,16,17)'\n",
      " 'InChI=1S/C19H26O2/c1-11-4-12(2)18(17(5-11)21-3)19(20)15-7-13-6-14(9-15)10-16(19)8-13/h4-5,13-16,20H,6-10H2,1-3H3']\n",
      "preds: ['InChI=1S/C21H21N5O2S/c1-15-7-8-19(17-6-4-11-22-20(15)17)30(27,28)25-13-9-16(10-14-25)21-24-23-18-5-2-3-12-26(18)21/h2-8,11-12,16H,9-10,13H2,1H3', 'InChI=1S/C18H19Cl2NO2/c1-12(2)9-10-23-14-6-3-5-13(11-14)18(22)21-17-15(19)7-4-8-16(17)20/h3-8,11-12H,9-10H2,1-2H3,(H,21,22)', 'InChI=1S/C21H29N5O/c27-21(26-13-11-25(12-14-26)15-16-25-17-22-18-23-25)20(18-7-3-4-8-18)19-9-5-2-6-10-19/h1-2,5-6,9-10,16-17,20H,3-4,7-8,11-15H2', 'InChI=1S/C13H20N2O6/c1-2-20-11(16)9-4-3-5-14(9)13(19)15-6-7-21-10(8-15)12(17)18/h9-10H,2-8H2,1H3,(H,17,18)', 'InChI=1S/C19H24O2/c1-11-3-14-8-17-7-13-4-14(9-17)10-18(16,15(13)5-12)19(20,2)17(16)21/h3,5-6,11-13,20H,4,7-10H2,1-2H3']\n",
      "Epoch 1 - avg_train_loss: 0.3737  time: 76335s\n",
      "Epoch 1 - Score: 23.2247\n",
      "Epoch 1 - Save Best Score: 23.2247 Model\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' : \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-special",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
